seed: 42
model_type: maxwell_B

model:
  layers: [128, 128, 128, 128, 6]   # bigger network, no dropout
  dropout: 0.0
  activation: relu

training:
  num_epochs: 500
  batch_size: 32
  learning_rate: 1e-3
  patience: 50

output_dir: ./trained_models